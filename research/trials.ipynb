open your vs code and create this file "trials.ipynb" in search folder and pest this code in each cell



# Core libraries
import os
import sys
from dotenv import load_dotenv
import pandas as pd
import numpy as np

# AI and ML libraries
from langchain_groq import ChatGroq
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_pinecone import PineconeVectorStore
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
  
# Vector database
from pinecone import Pinecone

# Web scraping and file processing
import requests
from PyPDF2 import PdfReader

print("ğŸ“¦ All libraries imported successfully!")
load_dotenv()
print("ğŸ” Environment variables loaded!")






# Initialize embeddings
print("ğŸ§  Initializing embeddings model...")
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': False}
)

print("âœ… Embeddings model initialized!")
print(f"Model: {embeddings.model_name}")
print(f"Device: {embeddings.model_kwargs['device']}")





# Initialize Pinecone
print("ğŸŒ² Initializing Pinecone vector database...")
try:
    pc = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))
    index = pc.Index('medical-chatbot')
    
    # Check index stats
    stats = index.describe_index_stats()
    print(f"âœ… Pinecone connected successfully!")
    print(f"ğŸ“Š Index stats: {stats['total_vector_count']} vectors")
    
except Exception as e:
    print(f"âŒ Pinecone initialization failed: {e}")
    print("âš  Please check your PINECONE_API_KEY")



# Initialize Groq chatbot
print("ğŸ¤– Initializing Groq AI model...")
try:
    groq_chatbot = ChatGroq(
        groq_api_key=os.getenv('GROQ_API_KEY'),
        model_name='llama-3.1-8b-instant',
        temperature=0.2,
        max_tokens=1000
    )
    print("âœ… Groq chatbot initialized successfully!")
    print(f"Model: llama-3.1-8b-instant")
    
except Exception as e:
    print(f"âŒ Groq initialization failed: {e}")
    print("âš  Please check your GROQ_API_KEY")
    groq_chatbot = None








# Initialize Google Gemini (optional fallback)
print("ğŸŒŸ Initializing Google Gemini AI...")
try:
    gemini_chatbot = ChatGoogleGenerativeAI(
        google_api_key=os.getenv('GOOGLE_API_KEY'),
        model="gemini-1.5-flash",
        temperature=0.3,
        max_output_tokens=1000
    )
    print("âœ… Gemini chatbot initialized successfully!")
    print(f"Model: gemini-1.5-flash")
    
except Exception as e:
    print(f"âš  Gemini initialization failed: {e}")
    print("â„¹ Gemini is optional - Groq will be primary model")
    gemini_chatbot = None










# Create vector store and retriever
try:
    vector_store = PineconeVectorStore(
        index=index, 
        embedding=embeddings
    )
    
    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}
    )
    
    print("âœ… Vector store and retriever created successfully!")
    print("ğŸ” Retriever configured for similarity search (k=3)")
    
except Exception as e:
    print(f"âŒ Vector store creation failed: {e}")
    retriever = None











# Test vector search with sample medical query
if retriever:
    test_query = "What are the symptoms of diabetes?"
    print(f"ğŸ§ª Testing retrieval with query: '{test_query}'")
    
    try:
        relevant_docs = retriever.invoke(test_query)
        print(f"âœ… Retrieved {len(relevant_docs)} documents")
        
        for i, doc in enumerate(relevant_docs, 1):
            print(f"\nğŸ“„ Document {i}:")
            print(f"Content preview: {doc.page_content[:200]}...")
            if hasattr(doc, 'metadata'):
                print(f"Metadata: {doc.metadata}")
    
    except Exception as e:
        print(f"âŒ Retrieval test failed: {e}")
else:
    print("âš  Skipping retrieval test - retriever not available")












def test_medical_response(question, model_name="groq"):
    """Test medical response generation"""
    
    # Get relevant context
    context = ""
    if retriever:
        try:
            relevant_docs = retriever.invoke(question)
            context = "\n\n".join([doc.page_content for doc in relevant_docs[:2]])
            print(f"ğŸ“š Retrieved context: {len(context)} characters")
        except Exception as e:
            print(f"âš  Context retrieval failed: {e}")
    
    # Create medical prompt
    medical_prompt = f"""You are an expert medical AI assistant. Provide ACCURATE and CONCISE medical information.

MEDICAL CONTEXT:
{context[:1200] if context else "General medical knowledge"}

QUESTION: {question}

INSTRUCTIONS:
- Maximum 250 words
- Use bullet points for clarity
- Include medical disclaimer
- Be accurate and helpful

RESPONSE:"""
    
    # Generate response
    try:
        if model_name.lower() == "groq" and groq_chatbot:
            response = groq_chatbot.invoke(medical_prompt)
            model_used = "Groq (llama-3.1-8b-instant)"
        elif model_name.lower() == "gemini" and gemini_chatbot:
            response = gemini_chatbot.invoke(medical_prompt)
            model_used = "Google Gemini (1.5-flash)"
        else:
            return "âŒ No AI model available"
        
        print(f"\nğŸ¤– Model used: {model_used}")
        print(f"ğŸ“ Response length: {len(response.content)} characters")
        return response.content
        
    except Exception as e:
        return f"âŒ Response generation failed: {str(e)}"

print("âœ… Medical response function ready for testing!")
















# Test with sample medical questions
test_questions = [
    "What are the early symptoms of diabetes?",
    "How can I prevent heart disease?",
    "What is the difference between type 1 and type 2 diabetes?"
]

for i, question in enumerate(test_questions, 1):
    print(f"\n{'='*60}")
    print(f"ğŸ§ª TEST {i}: {question}")
    print(f"{'='*60}")
    
    response = test_medical_response(question)
    print(f"\nğŸ’¬ Response:\n{response}")
    print(f"\n{'='*60}")










# Test Flask app components
import sys
import os

# Add parent directory to path
parent_dir = os.path.dirname(os.getcwd())
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

try:
    from app import app, initialize_ai_models
    print("âœ… Flask app imported successfully!")
    print(f"ğŸŒ App name: {app.name}")
    print(f"ğŸ”§ Debug mode: {app.debug}")
    
except Exception as e:
    print(f"âŒ Flask app import failed: {e}")
    print("â„¹ Make sure app.py is in the parent directory")










# Test app initialization and routes
try:
    # Configure app for testing
    app.config.update({
        'TESTING': True,
        'SERVER_NAME': 'localhost:5000',
        'APPLICATION_ROOT': '/',
        'PREFERRED_URL_SCHEME': 'http'
    })
    
    with app.app_context():
        print("ğŸ§ª Testing Flask app context...")
        
        # Test routes
        from flask import url_for
        
        routes = [
            ('index', '/'),
            ('health', '/health')
        ]
        
        for route_name, expected_path in routes:
            try:
                url = url_for(route_name)
                print(f"âœ… Route '{route_name}': {url}")
                # Verify the URL matches expected path
                if url.endswith(expected_path):
                    print(f"   ğŸ“ Path verification: PASSED")
                else:
                    print(f"   âš  Expected: {expected_path}, Got: {url}")
            except Exception as e:
                print(f"âŒ Route '{route_name}' failed: {e}")
        
        # Test app configuration
        print(f"\nğŸ”§ App Configuration:")
        print(f"   ğŸ“ App Name: {app.name}")
        print(f"   ğŸ› Debug Mode: {app.debug}")
        print(f"   ğŸ§ª Testing Mode: {app.config.get('TESTING', False)}")
        print(f"   ğŸŒ Server Name: {app.config.get('SERVER_NAME', 'Not set')}")
        
        # Test if routes are properly registered
        print(f"\nğŸ“‹ Registered Routes:")
        for rule in app.url_map.iter_rules():
            print(f"   {rule.rule} -> {rule.endpoint} [{', '.join(rule.methods)}]")
        
        print("âœ… Flask app context test completed!")
        
except Exception as e:
    print(f"âŒ App context test failed: {e}")
    print("ğŸ“‹ Troubleshooting tips:")
    print("   - Make sure app.py is properly configured")
    print("   - Check if all Flask routes are defined correctly")
    print("   - Verify environment variables are loaded")








# Performance benchmark
benchmark_questions = [
    "What is hypertension?",
    "Explain COVID-19 symptoms",
    "How to manage stress?"
]

results = []
print("ğŸƒâ€â™‚ Running performance benchmarks...\n")

for question in benchmark_questions:
    print(f"Testing: {question}")
    result = measure_response_time(question)
    results.append(result)
    print(f"â± Time: {result['response_time']}s | Words: {result['word_count']} | WPS: {result['words_per_second']}")
    print()

# Summary statistics
avg_time = sum(r['response_time'] for r in results) / len(results)
avg_words = sum(r['word_count'] for r in results) / len(results)
avg_wps = sum(r['words_per_second'] for r in results) / len(results)

print(f"ğŸ“Š Performance Summary:")
print(f"   Average Response Time: {avg_time:.2f} seconds")
print(f"   Average Word Count: {avg_words:.0f} words")
print(f"   Average Words/Second: {avg_wps:.2f} WPS")






# Check Vercel configuration
import json

# Check vercel.json
try:
    with open('../vercel.json', 'r') as f:
        vercel_config = json.load(f)
    
    print("âœ… Vercel configuration found!")
    print(f"ğŸ“„ vercel.json content:")
    print(json.dumps(vercel_config, indent=2))
    
except FileNotFoundError:
    print("âŒ vercel.json not found")
except Exception as e:
    print(f"âŒ Error reading vercel.json: {e}")






# Check requirements.txt
try:
    with open('../requirements.txt', 'r') as f:
        requirements = f.read().strip().split('\n')
    
    print("âœ… Requirements file found!")
    print(f"ğŸ“¦ Dependencies ({len(requirements)}):")
    for req in requirements:
        if req.strip():
            print(f"   - {req}")
    
except FileNotFoundError:
    print("âŒ requirements.txt not found")
except Exception as e:
    print(f"âŒ Error reading requirements.txt: {e}")









# Check API entry point
try:
    with open('../api/index.py', 'r') as f:
        api_content = f.read()
    
    print("âœ… API entry point found!")
    print(f"ğŸ“„ api/index.py content:")
    print(api_content[:300] + "..." if len(api_content) > 300 else api_content)
    
except FileNotFoundError:
    print("âŒ api/index.py not found")
except Exception as e:
    print(f"âŒ Error reading api/index.py: {e}")








# Final development summary
print("ğŸ¥ Medical Chatbot Development Summary")
print("=" * 50)
print("\nâœ… Completed Components:")
print("   ğŸ§  AI Models: Groq + Google Gemini")
print("   ğŸŒ² Vector Database: Pinecone with medical documents")
print("   ğŸ” RAG System: Document retrieval & context augmentation")
print("   ğŸŒ Flask Web App: Professional medical UI")
print("   ğŸš€ Vercel Deployment: Production-ready serverless")
print("   ğŸ” Security: Environment variables & gitignore")

print("\nğŸ“Š Current Status:")
print(f"   ğŸ¤– Groq Model: {'âœ… Active' if 'groq_chatbot' in globals() and groq_chatbot else 'âŒ Not initialized'}")
print(f"   ğŸŒŸ Gemini Model: {'âœ… Active' if 'gemini_chatbot' in globals() and gemini_chatbot else 'âŒ Not initialized'}")
print(f"   ğŸ” Retriever: {'âœ… Active' if 'retriever' in globals() and retriever else 'âŒ Not initialized'}")
print(f"   ğŸŒ² Pinecone: {'âœ… Connected' if 'index' in globals() else 'âŒ Not connected'}")

print("\nğŸš€ Next Steps:")
print("   1. Deploy to Vercel with environment variables")
print("   2. Test production deployment")
print("   3. Monitor performance and user feedback")
print("   4. Expand medical knowledge base")
print("   5. Add more AI model options")

print("\nğŸ¯ Ready for Production Deployment!")
print("ğŸ“± Repository: https://github.com/suman2026/generative-ai-medical-chatbot")
print("ğŸŒ Deploy at: https://vercel.com")
print("\n" + "=" * 50)













